{"version":3,"sources":["webpack:///path---tags-immersive-ace03004e5938362d355.js","webpack:///./.cache/json/tags-immersive.json"],"names":["webpackJsonp","361","module","exports","pathContext","posts","html","id","frontmatter","date","thumbnail","path","title","excerpt","tags","tagName"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,aAAeC,QAAUC,KAAA,wmCAAAC,GAAA,yGAAAC,aAAkwCC,KAAA,4BAAAC,UAAA,qCAAAC,KAAA,WAAAC,MAAA,UAAAC,QAAA,iIAAAC,MAAA,6BAAwSR,KAAA,63DAAmXC,GAAA,2GAAAC,aAAkrDC,KAAA,4BAAAC,UAAA,qCAAAC,KAAA,aAAAC,MAAA,YAAAC,QAAA,oIAAAC,MAAA,+CAAiUR,KAAA,k6CAAibC,GAAA,yGAAAC,aAA2oCC,KAAA,4BAAAC,UAAA,2HAAAC,KAAA,eAAAC,MAAA,cAAAC,QAAA,6LAAAC,MAAA,6BAAgcC,QAAA","file":"path---tags-immersive-ace03004e5938362d355.js","sourcesContent":["webpackJsonp([70218087590163],{\n\n/***/ 361:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"pathContext\":{\"posts\":[{\"html\":\"<h1>Gravity</h1>\\n<h2>Immersive installation</h2>\\n<blockquote>\\n<p><a href=\\\"http://wangxinyao-design.com/\\\">Xinyao Wang</a><br>\\n2017</p>\\n</blockquote>\\n<iframe src=\\\"https://player.vimeo.com/video/216230174\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>\\n<p><a href=\\\"https://vimeo.com/216230174\\\">Gravity</a> from <a href=\\\"https://vimeo.com/user33557684\\\">Xinyao Wang</a> on <a href=\\\"https://vimeo.com\\\">Vimeo</a>.</p>\\n<p>Gravity allows users to play in an magical version of mundane moments, where their movements can control the rules of physics. Combining simplified motion-capture suits, indoor position and projection mapping technology, users move their bodies to control objects in zero gravity. Working together they can change the world visually and aurally.</p>\\n<p>Toolkit: Unreal Engine, Openframework, Kinect, OSC, Socket.io, Android Studio, Syphon, Spout, TCP Syphon, TCP Spout, Motion Capture Suit, Resolume.\\n<br>\\n<a class=\\\"btn btn-outline-primary\\\" href=\\\"https://annekgoodfriend.github.io/Bootstrap_villageLIVE/\\\" role=\\\"button\\\">Project Page</a></p>\",\"id\":\"/home/travis/build/ITP-xStory/website/src/pages/projects/gravity.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2017-01-30T12:34:00+00:00\",\"thumbnail\":\"https://imgur.com/download/6cDzdkk\",\"path\":\"/gravity\",\"title\":\"Gravity\",\"excerpt\":\"Gravity allows users to play in an magical version of mundane moments, where their movements can control the rules of physics.\",\"tags\":[\"Experience\",\"Immersive\"]}},{\"html\":\"<h1>Skeletron</h1>\\n<h2>Predicting human pose in 3D using any camera</h2>\\n<blockquote>\\n<p><a href=\\\"www.orfleisher.com\\\">Or Fleisher</a>, ITP 2018<br>\\n<a href=\\\"www.drorayalon.com\\\">Dror Ayalon</a>, ITP 2018<br>\\n2018</p>\\n</blockquote>\\n<iframe width=\\\"560\\\" height=\\\"315\\\" src=\\\"https://www.youtube.com/embed/l_owi316cE8\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\\n<p>Skeletron is a system that predicts joints and human skeleton position in 3d from real-time video taken by any (cheap) RGB camera, such as a webcam. The system sends the data about the position of the human body to Unity, a 3D game development engine, to allow engineers, artists, and creative technologists to use it to develop digital experiences.</p>\\n<p>INGREDIENTS</p>\\n<ul>\\n<li>Machine Learning Model - <a href=\\\"http://gvv.mpi-inf.mpg.de/projects/VNect/\\\">http://gvv.mpi-inf.mpg.de/projects/VNect/</a></li>\\n<li>TensorFlow port - <a href=\\\"https://github.com/timctho/VNect-tensorflow\\\">https://github.com/timctho/VNect-tensorflow</a></li>\\n<li>Model prediction - Google TensorFlow</li>\\n<li>Data representation in 3D - <a href=\\\"https://unity3d.com/\\\">https://unity3d.com/</a></li>\\n</ul>\\n<h4>Press</h4>\\n<blockquote>\\n<p>\\\"Programmers use TensorFlow AI to turn any webcam into Microsoft Kinect\\\"<br>\\n<a href=\\\"https://thenextweb.com/artificial-intelligence/2018/01/30/programmers-use-tensorflow-ai-to-turn-any-webcam-into-microsoft-kinect/\\\">View article on thenextweb.com</a></p>\\n</blockquote>\\n<blockquote>\\n<p>\\\"Two AI developers have turned a simple webcam into a system that behaves just like a Microsoft Kinect using machine learning\\\"<br>\\n<a href=\\\"https://www.techradar.com/news/ai-developers-can-turn-any-webcam-into-a-kinect\\\">View article on techradar.com</a></p>\\n</blockquote>\\n<br>\\n<a class=\\\"btn btn-outline-primary\\\" href=\\\"http://orfleisher.com/portfolio-item/skeletron/\\\" role=\\\"button\\\">Project Page</a>\",\"id\":\"/home/travis/build/ITP-xStory/website/src/pages/projects/skeletron.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-01-30T12:34:00+00:00\",\"thumbnail\":\"https://imgur.com/download/Xb436pS\",\"path\":\"/skeletron\",\"title\":\"Skeletron\",\"excerpt\":\"Skeletron is a system that predicts joints and human skeleton position in 3d from real-time video taken by any (cheap) RGB camera\",\"tags\":[\"Machine Learning\",\"Tool\",\"Immersive\",\"3D\"]}},{\"html\":\"<h1>VillageLIVE</h1>\\n<h2>Augmented reality walking tour</h2>\\n<blockquote>\\n<p><a href=\\\"https://shirdavid.com/\\\">Shir David</a><br>\\n<a href=\\\"http://jordan-frand.squarespace.com/\\\">Jordan Frand</a><br>\\n<a href=\\\"https://www.annekgoodfriend.com/\\\">Anne K Goodfriend</a><br>\\n2017</p>\\n</blockquote>\\n<iframe width=\\\"560\\\" height=\\\"315\\\" src=\\\"https://www.youtube.com/embed/vID0Cs3Ue28\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\\n<p>VillageLIVE is an augmented reality walking tour through the streets of New York City told through the archive of Nelson Sullivan, a documentarian of the city’s queer scene in the 1980s. VillageLIVE brings past narratives back to life in the streets where prominent figures of the city’s queer history once flourished. We have chosen a selection of Nelson’s videos to set the scene and to tell a narrative that includes stories of gentrification, of the notion of public safety for the queer community, and of the revolutionary roots of NYC’s queer society, dating back to the Stonewall Riots in 1969.We have also developed this project as an AR app and 360 video web experience through a grant from A+E Networks, in partnership with NYC Media Lab. As we continue to develop you can see a demonstration of the current state of the app here.</p>\\n<br>\\n<a class=\\\"btn btn-outline-primary\\\" href=\\\"https://annekgoodfriend.github.io/Bootstrap_villageLIVE/\\\" role=\\\"button\\\">Project Page</a>\",\"id\":\"/home/travis/build/ITP-xStory/website/src/pages/projects/village.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2017-01-30T12:34:00+00:00\",\"thumbnail\":\"https://static1.squarespace.com/static/56c39df6f850822ff68ac352/t/5a7a021fe4966b5472d1b6a6/1517945394337/villagelive.gif\",\"path\":\"/Villagelive\",\"title\":\"VillageLIVE\",\"excerpt\":\"VillageLIVE is an augmented reality walking tour through the streets of New York City told through the archive of Nelson Sullivan, a documentarian of the city’s queer scene in the 1980s.\",\"tags\":[\"Experience\",\"Immersive\"]}}],\"tagName\":\"Immersive\"}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---tags-immersive-ace03004e5938362d355.js","module.exports = {\"pathContext\":{\"posts\":[{\"html\":\"<h1>Gravity</h1>\\n<h2>Immersive installation</h2>\\n<blockquote>\\n<p><a href=\\\"http://wangxinyao-design.com/\\\">Xinyao Wang</a><br>\\n2017</p>\\n</blockquote>\\n<iframe src=\\\"https://player.vimeo.com/video/216230174\\\" width=\\\"640\\\" height=\\\"360\\\" frameborder=\\\"0\\\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>\\n<p><a href=\\\"https://vimeo.com/216230174\\\">Gravity</a> from <a href=\\\"https://vimeo.com/user33557684\\\">Xinyao Wang</a> on <a href=\\\"https://vimeo.com\\\">Vimeo</a>.</p>\\n<p>Gravity allows users to play in an magical version of mundane moments, where their movements can control the rules of physics. Combining simplified motion-capture suits, indoor position and projection mapping technology, users move their bodies to control objects in zero gravity. Working together they can change the world visually and aurally.</p>\\n<p>Toolkit: Unreal Engine, Openframework, Kinect, OSC, Socket.io, Android Studio, Syphon, Spout, TCP Syphon, TCP Spout, Motion Capture Suit, Resolume.\\n<br>\\n<a class=\\\"btn btn-outline-primary\\\" href=\\\"https://annekgoodfriend.github.io/Bootstrap_villageLIVE/\\\" role=\\\"button\\\">Project Page</a></p>\",\"id\":\"/home/travis/build/ITP-xStory/website/src/pages/projects/gravity.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2017-01-30T12:34:00+00:00\",\"thumbnail\":\"https://imgur.com/download/6cDzdkk\",\"path\":\"/gravity\",\"title\":\"Gravity\",\"excerpt\":\"Gravity allows users to play in an magical version of mundane moments, where their movements can control the rules of physics.\",\"tags\":[\"Experience\",\"Immersive\"]}},{\"html\":\"<h1>Skeletron</h1>\\n<h2>Predicting human pose in 3D using any camera</h2>\\n<blockquote>\\n<p><a href=\\\"www.orfleisher.com\\\">Or Fleisher</a>, ITP 2018<br>\\n<a href=\\\"www.drorayalon.com\\\">Dror Ayalon</a>, ITP 2018<br>\\n2018</p>\\n</blockquote>\\n<iframe width=\\\"560\\\" height=\\\"315\\\" src=\\\"https://www.youtube.com/embed/l_owi316cE8\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\\n<p>Skeletron is a system that predicts joints and human skeleton position in 3d from real-time video taken by any (cheap) RGB camera, such as a webcam. The system sends the data about the position of the human body to Unity, a 3D game development engine, to allow engineers, artists, and creative technologists to use it to develop digital experiences.</p>\\n<p>INGREDIENTS</p>\\n<ul>\\n<li>Machine Learning Model - <a href=\\\"http://gvv.mpi-inf.mpg.de/projects/VNect/\\\">http://gvv.mpi-inf.mpg.de/projects/VNect/</a></li>\\n<li>TensorFlow port - <a href=\\\"https://github.com/timctho/VNect-tensorflow\\\">https://github.com/timctho/VNect-tensorflow</a></li>\\n<li>Model prediction - Google TensorFlow</li>\\n<li>Data representation in 3D - <a href=\\\"https://unity3d.com/\\\">https://unity3d.com/</a></li>\\n</ul>\\n<h4>Press</h4>\\n<blockquote>\\n<p>\\\"Programmers use TensorFlow AI to turn any webcam into Microsoft Kinect\\\"<br>\\n<a href=\\\"https://thenextweb.com/artificial-intelligence/2018/01/30/programmers-use-tensorflow-ai-to-turn-any-webcam-into-microsoft-kinect/\\\">View article on thenextweb.com</a></p>\\n</blockquote>\\n<blockquote>\\n<p>\\\"Two AI developers have turned a simple webcam into a system that behaves just like a Microsoft Kinect using machine learning\\\"<br>\\n<a href=\\\"https://www.techradar.com/news/ai-developers-can-turn-any-webcam-into-a-kinect\\\">View article on techradar.com</a></p>\\n</blockquote>\\n<br>\\n<a class=\\\"btn btn-outline-primary\\\" href=\\\"http://orfleisher.com/portfolio-item/skeletron/\\\" role=\\\"button\\\">Project Page</a>\",\"id\":\"/home/travis/build/ITP-xStory/website/src/pages/projects/skeletron.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2018-01-30T12:34:00+00:00\",\"thumbnail\":\"https://imgur.com/download/Xb436pS\",\"path\":\"/skeletron\",\"title\":\"Skeletron\",\"excerpt\":\"Skeletron is a system that predicts joints and human skeleton position in 3d from real-time video taken by any (cheap) RGB camera\",\"tags\":[\"Machine Learning\",\"Tool\",\"Immersive\",\"3D\"]}},{\"html\":\"<h1>VillageLIVE</h1>\\n<h2>Augmented reality walking tour</h2>\\n<blockquote>\\n<p><a href=\\\"https://shirdavid.com/\\\">Shir David</a><br>\\n<a href=\\\"http://jordan-frand.squarespace.com/\\\">Jordan Frand</a><br>\\n<a href=\\\"https://www.annekgoodfriend.com/\\\">Anne K Goodfriend</a><br>\\n2017</p>\\n</blockquote>\\n<iframe width=\\\"560\\\" height=\\\"315\\\" src=\\\"https://www.youtube.com/embed/vID0Cs3Ue28\\\" frameborder=\\\"0\\\" allow=\\\"autoplay; encrypted-media\\\" allowfullscreen></iframe>\\n<p>VillageLIVE is an augmented reality walking tour through the streets of New York City told through the archive of Nelson Sullivan, a documentarian of the city’s queer scene in the 1980s. VillageLIVE brings past narratives back to life in the streets where prominent figures of the city’s queer history once flourished. We have chosen a selection of Nelson’s videos to set the scene and to tell a narrative that includes stories of gentrification, of the notion of public safety for the queer community, and of the revolutionary roots of NYC’s queer society, dating back to the Stonewall Riots in 1969.We have also developed this project as an AR app and 360 video web experience through a grant from A+E Networks, in partnership with NYC Media Lab. As we continue to develop you can see a demonstration of the current state of the app here.</p>\\n<br>\\n<a class=\\\"btn btn-outline-primary\\\" href=\\\"https://annekgoodfriend.github.io/Bootstrap_villageLIVE/\\\" role=\\\"button\\\">Project Page</a>\",\"id\":\"/home/travis/build/ITP-xStory/website/src/pages/projects/village.md absPath of file >>> MarkdownRemark\",\"frontmatter\":{\"date\":\"2017-01-30T12:34:00+00:00\",\"thumbnail\":\"https://static1.squarespace.com/static/56c39df6f850822ff68ac352/t/5a7a021fe4966b5472d1b6a6/1517945394337/villagelive.gif\",\"path\":\"/Villagelive\",\"title\":\"VillageLIVE\",\"excerpt\":\"VillageLIVE is an augmented reality walking tour through the streets of New York City told through the archive of Nelson Sullivan, a documentarian of the city’s queer scene in the 1980s.\",\"tags\":[\"Experience\",\"Immersive\"]}}],\"tagName\":\"Immersive\"}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/tags-immersive.json\n// module id = 361\n// module chunks = 70218087590163"],"sourceRoot":""}