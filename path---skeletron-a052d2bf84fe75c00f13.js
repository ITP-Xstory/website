webpackJsonp([0x5c9b1cd56a8a],{358:function(e,t){e.exports={data:{markdownRemark:{html:'<h1>Skeletron</h1>\n<h2>Predicting human pose in 3D using any camera</h2>\n<blockquote>\n<p><a href="www.orfleisher.com">Or Fleisher</a>, ITP 2018<br>\n<a href="www.drorayalon.com">Dror Ayalon</a>, ITP 2018<br>\n2018</p>\n</blockquote>\n<iframe width="560" height="315" src="https://www.youtube.com/embed/l_owi316cE8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>\n<p>Skeletron is a system that predicts joints and human skeleton position in 3d from real-time video taken by any (cheap) RGB camera, such as a webcam. The system sends the data about the position of the human body to Unity, a 3D game development engine, to allow engineers, artists, and creative technologists to use it to develop digital experiences.</p>\n<p>INGREDIENTS</p>\n<ul>\n<li>Machine Learning Model - <a href="http://gvv.mpi-inf.mpg.de/projects/VNect/">http://gvv.mpi-inf.mpg.de/projects/VNect/</a></li>\n<li>TensorFlow port - <a href="https://github.com/timctho/VNect-tensorflow">https://github.com/timctho/VNect-tensorflow</a></li>\n<li>Model prediction - Google TensorFlow</li>\n<li>Data representation in 3D - <a href="https://unity3d.com/">https://unity3d.com/</a></li>\n</ul>\n<h4>Press</h4>\n<blockquote>\n<p>"Programmers use TensorFlow AI to turn any webcam into Microsoft Kinect"<br>\n<a href="https://thenextweb.com/artificial-intelligence/2018/01/30/programmers-use-tensorflow-ai-to-turn-any-webcam-into-microsoft-kinect/">View article on thenextweb.com</a></p>\n</blockquote>\n<blockquote>\n<p>"Two AI developers have turned a simple webcam into a system that behaves just like a Microsoft Kinect using machine learning"<br>\n<a href="https://www.techradar.com/news/ai-developers-can-turn-any-webcam-into-a-kinect">View article on techradar.com</a></p>\n</blockquote>\n<br>\n<a class="btn btn-outline-primary" href="http://orfleisher.com/portfolio-item/skeletron/" role="button">Project Page</a>',frontmatter:{title:"Skeletron",date:"January 30, 2018",path:"/skeletron",tags:["Machine Learning","Tool","Immersive","3D"],excerpt:"Skeletron is a system that predicts joints and human skeleton position in 3d from real-time video taken by any (cheap) RGB camera"}}},pathContext:{prev:{html:'<h1>Kinectron</h1>\n<h2>A Realtime Peer Server for Kinect 2</h2>\n<blockquote>\n<p><a href="http://lisajamhoury.com/">Lisa Jamhoury</a>, ITP 2017<br>\n<a href="https://github.com/vanevery">Shawn Van Every</a>, ITP</p>\n<blockquote>\n<p>Additional collaborators: <a href="http://anothersideproject.co/">Stephanie Koltun</a>, <a href="www.orfleisher.com">Or Fleisher</a> and <a href="http://montoyamoraga.io/">Aarón Montoya-Moraga</a></p>\n</blockquote>\n</blockquote>\n<blockquote>\n<p>2017</p>\n</blockquote>\n<p>Kinectron is a node-based library that broadcasts Kinect2 data over a peer connection. It builds on the Node Kinect2 and PeerJS libraries.<br>\nKinectron sends Kinect depth, color and skeletal data over a peer network. It can be used in a number of ways.<br>\nKinectron has two components--an electron application to broadcast Kinect2 data over a peer connection, and a client-side API to request and receive Kinect2 data over a peer connection.</p>\n<p><a class="btn btn-outline-primary" href="https://kinectron.github.io/" role="button">Project Page</a> <a class="btn btn-outline-primary" href="https://github.com/kinectron/kinectron" role="button">GitHub Repository</a></p>',id:"/home/travis/build/ITP-xStory/website/src/pages/projects/kinectron.md absPath of file >>> MarkdownRemark",frontmatter:{date:"2018-05-23T12:34:00+00:00",thumbnail:"https://kinectron.github.io/img/depth.gif",path:"/kinectron",title:"Kinectron",excerpt:"Kinectron is a node-based library that broadcasts Kinect2 data over a peer connection. It builds on the Node Kinect2 and PeerJS libraries.",tags:["Tool"]}},next:{html:'<h1>VillageLIVE</h1>\n<h2>Augmented reality walking tour</h2>\n<blockquote>\n<p><a href="https://shirdavid.com/">Shir David</a><br>\n<a href="http://jordan-frand.squarespace.com/">Jordan Frand</a><br>\n<a href="https://www.annekgoodfriend.com/">Anne K Goodfriend</a><br>\n2017</p>\n</blockquote>\n<iframe width="560" height="315" src="https://www.youtube.com/embed/vID0Cs3Ue28" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>\n<p>VillageLIVE is an augmented reality walking tour through the streets of New York City told through the archive of Nelson Sullivan, a documentarian of the city’s queer scene in the 1980s. VillageLIVE brings past narratives back to life in the streets where prominent figures of the city’s queer history once flourished. We have chosen a selection of Nelson’s videos to set the scene and to tell a narrative that includes stories of gentrification, of the notion of public safety for the queer community, and of the revolutionary roots of NYC’s queer society, dating back to the Stonewall Riots in 1969.We have also developed this project as an AR app and 360 video web experience through a grant from A+E Networks, in partnership with NYC Media Lab. As we continue to develop you can see a demonstration of the current state of the app here.</p>\n<br>\n<a class="btn btn-outline-primary" href="https://annekgoodfriend.github.io/Bootstrap_villageLIVE/" role="button">Project Page</a>',id:"/home/travis/build/ITP-xStory/website/src/pages/projects/village.md absPath of file >>> MarkdownRemark",frontmatter:{date:"2017-01-30T12:34:00+00:00",thumbnail:"https://static1.squarespace.com/static/56c39df6f850822ff68ac352/t/5a7a021fe4966b5472d1b6a6/1517945394337/villagelive.gif",path:"/Villagelive",title:"VillageLIVE",excerpt:"VillageLIVE is an augmented reality walking tour through the streets of New York City told through the archive of Nelson Sullivan, a documentarian of the city’s queer scene in the 1980s.",tags:["Experience","Immersive"]}}}}}});
//# sourceMappingURL=path---skeletron-a052d2bf84fe75c00f13.js.map